{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect 4 board class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Class for the connect 4 game:\n",
    "Number of rows = 4, Number of columns = 5\n",
    "The board will be a 2D Numpy array consisting of 0s, 1s, and 2s (where 1 is player 1, 2 is player 2, 0 is an empty slot)\n",
    "Rewards are as follows: {win: 1, draw: -0.5, lose: -1} (we want to maximize winning)\n",
    "'''\n",
    "\n",
    "class C4:\n",
    "    def __init__(self):\n",
    "        self.width = 7\n",
    "        self.height = 6\n",
    "        self.state = np.zeros([self.height, self.width], dtype=np.uint8)\n",
    "        self.players = {'P1': 1, 'P2': 2}\n",
    "        self.rewards = {'Win': 1, 'Draw': -0.5, 'Lose': -1}\n",
    "        self.Finished = False\n",
    "        self.actions = [0, 1, 2, 3, 4, 5, 6]\n",
    "        \n",
    "    def resetGame(self):\n",
    "        self.__init__()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Function for returning the columns which are not full (the topmost slot in the column should be a 0)\n",
    "    '''\n",
    "\n",
    "    def free_cols(self):\n",
    "        return [col for col in range(self.width) if self.state[0, col] == 0]\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Function for checking winning conditions\n",
    "    Input will be the player, row & col of move played\n",
    "    Search for win in the col, row and the two diagonals\n",
    "    '''\n",
    "    \n",
    "    def check_vertical(self, sub_str, col):\n",
    "        return sub_str in self.state[:, col].astype(str)\n",
    "\n",
    "    \n",
    "    def check_horizontal(self, sub_str, row):\n",
    "        return sub_str in self.state[row, :].astype(str)\n",
    "    \n",
    "    def check_diagonal(self, sub_str, row, col):\n",
    "        left_diagonal = ''\n",
    "\n",
    "        #first go to the lefmost point in the left diagonal of the row, col\n",
    "        i = row - min(row, col)\n",
    "        j = col - min(row, col)\n",
    "        while i < self.height and j < self.width:\n",
    "            left_diagonal += f'{self.state[row, col]} '\n",
    "            i+=1\n",
    "            j+=1\n",
    "        \n",
    "        right_diagonal = ''\n",
    "\n",
    "        #first go to the rightmost point in the right diagonal of the row, col\n",
    "        i  = row - min(row, col)\n",
    "        j = col + min(row, col)\n",
    "        while i < self.height and j > 0:\n",
    "            right_diagonal += f'{self.state[row, col]} '\n",
    "            i+=1\n",
    "            j-=1\n",
    "\n",
    "        return sub_str in left_diagonal or sub_str in right_diagonal\n",
    "    \n",
    "    #we just need to check if the board is full \n",
    "    def is_draw(self):\n",
    "        for col in range(self.width):\n",
    "            if self.state[0][col] == 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def check_win(self, player, row, col):\n",
    "        win_substr = ' '.join([self.players[player]] * 4)\n",
    "        #if either of the conditions passes, the current player has won\n",
    "        if self.check_vertical(win_substr, col) or self.check_horizontal(win_substr, row) or self.check_diagonal(win_substr, row, col):\n",
    "            self.Finished = True\n",
    "        \n",
    "        if self.Finished:\n",
    "            return self.rewards['Win']\n",
    "        elif self.is_draw():\n",
    "            return self.rewards['Draw']\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    '''\n",
    "    Function for making a move.\n",
    "    If the move is valid, drop the token at the lowest empty space in the column\n",
    "    Once the move is made, check winning conditions\n",
    "\n",
    "    '''\n",
    "\n",
    "    def move(self, player, col):\n",
    "        #check if there is free space in the column\n",
    "        if self.state[0, col] == 0:\n",
    "            row = np.where(self.state[:, col])[0][-1]\n",
    "            self.state[row, col] = self.players[player]\n",
    "            return self.state.copy(), self.check_win(player, row, col)\n",
    "\n",
    "\n",
    "        else:\n",
    "            print('Invalid move')\n",
    "            return self.state.copy(), 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Replay Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Experience Replay will be used to train.\n",
    "Any transition that is observed will be stored: (state, action taken, reward received, next state)\n",
    "We can randomly sample from this list to use for training instead of training on each state-action pair\n",
    "'''\n",
    "\n",
    "import random\n",
    "\n",
    "class Expr_Replay:\n",
    "    def __init__(self):\n",
    "        self.store = []\n",
    "\n",
    "    def sample(self, num):\n",
    "        return random.sample(self.store, num)\n",
    "    \n",
    "    def add(self, transition):\n",
    "        self.store.append(transition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network to approximate the Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        #convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
    "\n",
    "        #fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 6 * 7, 42)\n",
    "        self.fc2 = nn.Linear(42, 42)\n",
    "        self.out = nn.Linear(42, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.batch_size = 256\n",
    "        self.gamma = 0.9\n",
    "        self.eps_start = 0.9\n",
    "        self.eps_end = 0.05\n",
    "        self.eps_decay = 2000\n",
    "\n",
    "        self.env = C4()\n",
    "        self.num_actions = self.env.width\n",
    "\n",
    "        #initializing the two networks - main and target\n",
    "        self.main_net = DQN()\n",
    "        self.target_net = DQN()\n",
    "\n",
    "        self.target_net.load_state_dict(self.main_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        #use Adam for optimizing the network\n",
    "        self.optimizer = optim.Adam(self.main_net.parameters())\n",
    "\n",
    "    def epsilon_greedy(self, state, free_actions, steps_done, training):\n",
    "        \n",
    "        state = torch.tensor(state, dtype=torch.float).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "        if training:\n",
    "            threshold = self.eps_end + (self.eps_start - self.eps_end) * math.exp(-1 * steps_done / self.eps_decay)\n",
    "        else:\n",
    "            threshold = 0\n",
    "\n",
    "        #if random eps is less than threshold (calc using decay), then explore\n",
    "        #if > than, then use the main net to exploit\n",
    "        if random.random() < threshold:\n",
    "            return random.choice(free_actions)\n",
    "        else:\n",
    "            actions = self.main_net(state)[0, :]\n",
    "            vals = [actions[i] for i in free_actions]\n",
    "            return free_actions[np.argmax(vals)]\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
